{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/56137/56137/blob/main/MaxGPT_1_(1)_0_by_maxesqerra_0_by_maxesqerra_0_by_maxesqerra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09e2cd29-4821-4a2b-950e-69bc24404d0b",
      "metadata": {
        "id": "09e2cd29-4821-4a2b-950e-69bc24404d0b",
        "outputId": "57f346aa-878f-425a-af41-c8d49f726996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu128)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu128)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu128)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.1.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.4.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.12/dist-packages (0.48.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.3.3)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.18)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (7.1.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu128)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.23.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.20.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.7.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from wandb) (25.0)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (6.33.2)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.12.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.32.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.47.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb) (4.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.41.5)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb) (2025.10.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (2.3.1)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tensorboard) (11.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (80.9.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# CELDA 1: Instalar dependencias en Jupyter\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install transformers datasets accelerate peft bitsandbytes scipy\n",
        "!pip install wandb tensorboard scikit-learn pandas numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"instruction\": \"ExplÃ­came quÃ© es el flujo de caja como si tuviera 15 aÃ±os.\",\n",
        "  \"output\": \"El flujo de caja es como ver cuÃ¡nto dinero entra y cuÃ¡nto sale...\"\n",
        "}"
      ],
      "metadata": {
        "id": "vQ00QHSlFkGY"
      },
      "id": "vQ00QHSlFkGY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2669115d-bdff-4180-9d13-de70d071f15c",
      "metadata": {
        "id": "2669115d-bdff-4180-9d13-de70d071f15c",
        "outputId": "433a5547-dd30-4a59-d21c-d48a845443f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… PyTorch version: 2.8.0+cu128\n",
            "âœ… CUDA available: True\n",
            "âœ… GPU name: NVIDIA GeForce RTX 4090\n",
            "âœ… CUDA version: 12.8\n",
            "âœ… GPU Memory: 25.25 GB\n"
          ]
        }
      ],
      "source": [
        "# CELDA 2: Verificar instalaciÃ³n de PyTorch con CUDA\n",
        "import torch\n",
        "print(f\"âœ… PyTorch version: {torch.__version__}\")\n",
        "print(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"âœ… GPU name: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"âœ… CUDA version: {torch.version.cuda}\")\n",
        "print(f\"âœ… GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3a4c5db-fd62-4973-b097-3da3da1a7ce0",
      "metadata": {
        "id": "a3a4c5db-fd62-4973-b097-3da3da1a7ce0",
        "outputId": "a1453eab-00d6-4fbd-cc98-077e8952347e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ Creado: maxgpt_project\n",
            "ğŸ“ Creado: maxgpt_project/data\n",
            "ğŸ“ Creado: maxgpt_project/models\n",
            "ğŸ“ Creado: maxgpt_project/training\n",
            "ğŸ“ Creado: maxgpt_project/outputs\n",
            "ğŸ“ Creado: maxgpt_project/deploy\n",
            "\n",
            "âœ… Estructura de carpetas lista:\n",
            "total 10869\n",
            "drwxrwxrwx 8 root root 3000101 Dec  6 07:04 .\n",
            "drwxrwxrwx 5 root root 3000318 Dec  6 07:39 ..\n",
            "drwxrwxrwx 4 root root 2041840 Dec  6 07:21 backups\n",
            "drwxrwxrwx 2 root root 1022792 Dec  6 06:21 data\n",
            "drwxrwxrwx 2 root root       1 Dec  6 06:21 deploy\n",
            "drwxrwxrwx 5 root root 2062301 Dec  6 07:04 models\n",
            "drwxrwxrwx 5 root root       1 Dec  6 07:16 outputs\n",
            "drwxrwxrwx 2 root root       1 Dec  6 06:21 training\n"
          ]
        }
      ],
      "source": [
        "# CELDA 3: Crear estructura de carpetas\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Crear directorios necesarios\n",
        "directorios = [\n",
        "    \"maxgpt_project\",\n",
        "    \"maxgpt_project/data\",\n",
        "    \"maxgpt_project/models\",\n",
        "    \"maxgpt_project/training\",\n",
        "    \"maxgpt_project/outputs\",\n",
        "    \"maxgpt_project/deploy\"\n",
        "]\n",
        "\n",
        "for directorio in directorios:\n",
        "    os.makedirs(directorio, exist_ok=True)\n",
        "    print(f\"ğŸ“ Creado: {directorio}\")\n",
        "\n",
        "print(\"\\nâœ… Estructura de carpetas lista:\")\n",
        "!ls -la maxgpt_project/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "051ac6c7-f0f3-4ea5-95bb-3c437dfa5dd8",
      "metadata": {
        "id": "051ac6c7-f0f3-4ea5-95bb-3c437dfa5dd8",
        "outputId": "8918c885-47ca-4c3c-974f-4af8b040db96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”„ Generando dataset MaxGPT con 400 ejemplos...\n",
            "âœ… Dataset guardado: 400 ejemplos\n",
            "ğŸ“Š Muestra del dataset:\n",
            "\n",
            "--- Ejemplo 1 ---\n",
            "Prompt: <|system|>Eres MaxGPT, experto en marketing digital, growth hacking, automatizaciÃ³n de negocios y mo...\n",
            "Completion: Sistema: Trigger â†’ AcciÃ³n â†’ CondiciÃ³n â†’ Resultado. Ejemplo: Nuevo lead â†’ Email automÃ¡tico â†’ Seguimie...\n",
            "\n",
            "--- Ejemplo 2 ---\n",
            "Prompt: <|system|>Eres MaxGPT, experto en marketing digital, growth hacking, automatizaciÃ³n de negocios y mo...\n",
            "Completion: Sistema efectivo: Atraer â†’ Convertir â†’ Vender â†’ Entregar â†’ Encantar. Automatiza cada paso. Habilidad...\n"
          ]
        }
      ],
      "source": [
        "# CELDA 4: Generar dataset optimizado para MaxGPT\n",
        "import json\n",
        "import random\n",
        "\n",
        "def generar_dataset_maxgpt():\n",
        "    \"\"\"Genera 400 ejemplos de alta calidad para MaxGPT\"\"\"\n",
        "\n",
        "    categorias = {\n",
        "        \"marketing_digital\": [\n",
        "            \"Â¿CÃ³mo puedo aumentar las conversiones de mi ecommerce?\",\n",
        "            \"Â¿QuÃ© estrategias de SEO funcionan mejor en 2024?\",\n",
        "            \"Â¿CÃ³mo optimizo mis campaÃ±as de Facebook Ads?\",\n",
        "            \"Â¿QuÃ© mÃ©tricas debo seguir para medir Ã©xito?\",\n",
        "            \"Â¿CÃ³mo creo un funnel de ventas efectivo?\",\n",
        "            \"Â¿QuÃ© herramientas de marketing automation recomiendas?\",\n",
        "            \"Â¿CÃ³mo reduzco el costo por adquisiciÃ³n?\",\n",
        "            \"Â¿QuÃ© contenido genera mÃ¡s engagement en redes?\",\n",
        "            \"Â¿CÃ³mo construyo una marca personal sÃ³lida?\",\n",
        "            \"Â¿QuÃ© estrategias de email marketing tienen mejor ROI?\"\n",
        "        ],\n",
        "\n",
        "        \"growth_hacking\": [\n",
        "            \"Â¿CÃ³mo consigo mis primeros 100 clientes?\",\n",
        "            \"Â¿QuÃ© tÃ©cnicas de viralizaciÃ³n uso?\",\n",
        "            \"Â¿CÃ³mo optimizo mi tasa de conversiÃ³n?\",\n",
        "            \"Â¿QuÃ© canales de adquisiciÃ³n son mÃ¡s escalables?\",\n",
        "            \"Â¿CÃ³mo automatizo la prospecciÃ³n de leads?\",\n",
        "            \"Â¿QuÃ© experimentos debo hacer para crecer rÃ¡pido?\",\n",
        "            \"Â¿CÃ³mo reduzco la tasa de abandono?\",\n",
        "            \"Â¿QuÃ© programas de referidos funcionan?\",\n",
        "            \"Â¿CÃ³mo monetizo una audiencia rÃ¡pidamente?\",\n",
        "            \"Â¿QuÃ© KPIs debo trackear para growth?\"\n",
        "        ],\n",
        "\n",
        "        \"automatizacion\": [\n",
        "            \"Â¿CÃ³mo automatizo mi negocio online?\",\n",
        "            \"Â¿QuÃ© procesos debo automatizar primero?\",\n",
        "            \"Â¿CÃ³mo integro mis herramientas de marketing?\",\n",
        "            \"Â¿QuÃ© bots pueden ahorrarme tiempo?\",\n",
        "            \"Â¿CÃ³mo automatizo el servicio al cliente?\",\n",
        "            \"Â¿QuÃ© scripts de Python me recomiendas?\",\n",
        "            \"Â¿CÃ³mo programo tareas recurrentes?\",\n",
        "            \"Â¿QuÃ© APIs debo conectar en mi negocio?\",\n",
        "            \"Â¿CÃ³mo hago web scraping Ã©tico?\",\n",
        "            \"Â¿QuÃ© sistemas de notificaciÃ³n automatizo?\"\n",
        "        ],\n",
        "\n",
        "        \"monetizacion\": [\n",
        "            \"Â¿CÃ³mo genero $1000 mensuales online?\",\n",
        "            \"Â¿QuÃ© productos digitales venden mejor?\",\n",
        "            \"Â¿CÃ³mo implemento un modelo de suscripciÃ³n?\",\n",
        "            \"Â¿QuÃ© estrategias de precios maximizan ganancias?\",\n",
        "            \"Â¿CÃ³mo aumento el valor de vida del cliente?\",\n",
        "            \"Â¿QuÃ© ingresos pasivos puedo crear?\",\n",
        "            \"Â¿CÃ³mo escalo de $1k a $10k mensuales?\",\n",
        "            \"Â¿QuÃ© nichos son mÃ¡s rentables en 2024?\",\n",
        "            \"Â¿CÃ³mo diversifico mis fuentes de ingreso?\",\n",
        "            \"Â¿QuÃ© tÃ©cnicas de venta online son mÃ¡s efectivas?\"\n",
        "        ],\n",
        "\n",
        "        \"creacion_contenido\": [\n",
        "            \"Â¿QuÃ© tipo de contenido genera mÃ¡s leads?\",\n",
        "            \"Â¿CÃ³mo creo un calendario editorial efectivo?\",\n",
        "            \"Â¿QuÃ© plataformas son mejores para mi audiencia?\",\n",
        "            \"Â¿CÃ³mo reciclo contenido de forma inteligente?\",\n",
        "            \"Â¿QuÃ© formato de contenido tiene mÃ¡s engagement?\",\n",
        "            \"Â¿CÃ³mo optimizo mi blog para conversiones?\",\n",
        "            \"Â¿QuÃ© herramientas uso para crear contenido?\",\n",
        "            \"Â¿CÃ³mo mido el ROI de mi contenido?\",\n",
        "            \"Â¿QuÃ© estrategias de contenido son virales?\",\n",
        "            \"Â¿CÃ³mo convierto contenido en ventas?\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # Respuestas estructuradas por categorÃ­a\n",
        "    plantillas_respuestas = {\n",
        "        \"marketing_digital\": [\n",
        "            \"Estrategia clave: 1) Segmenta tu audiencia, 2) Testea mensajes diferentes, 3) Optimiza lo que funciona, 4) Escala los winners. ROI objetivo: 3-5x.\",\n",
        "            \"EnfÃ³cate en: Propuesta de valor clara + funnel optimizado + remarketing + anÃ¡lisis constante. MÃ©trica clave: CAC < LTV/3.\",\n",
        "            \"Prioriza: ConversiÃ³n sobre trÃ¡fico, retenciÃ³n sobre adquisiciÃ³n, calidad sobre cantidad. Herramienta esencial: Google Analytics + Hotjar.\",\n",
        "            \"TÃ©cnica probada: Contenido educativo + lead magnet + email sequence + webinar + oferta. ConversiÃ³n esperada: 5-10%.\",\n",
        "            \"Sistema efectivo: Atraer â†’ Convertir â†’ Vender â†’ Entregar â†’ Encantar. Automatiza cada paso.\"\n",
        "        ],\n",
        "\n",
        "        \"growth_hacking\": [\n",
        "            \"Growth hack: Producto que se comparte solo + incentivos virales + loop automÃ¡tico. Ejemplo: Dropbox (referidos = mÃ¡s espacio).\",\n",
        "            \"MÃ©todo: Encuentra un canal infravalorado, domÃ­nalo, escala, luego pasa al siguiente. Ejemplo: Airbnb + Craigslist.\",\n",
        "            \"TÃ¡ctica: Da algo de alto valor gratis, captura emails, nutre relaciÃ³n, vende producto premium. ConversiÃ³n tÃ­pica: 3-7%.\",\n",
        "            \"Estrategia: Alianzas win-win, co-marketing, programas afiliados, cross-promotions. Crecimiento: 20-40% mensual.\",\n",
        "            \"TÃ©cnica: Uso inteligente de APIs, integraciones, automatizaciones, data scraping Ã©tico. Eficiencia: 10x.\"\n",
        "        ],\n",
        "\n",
        "        \"automatizacion\": [\n",
        "            \"Automatiza: 1) ProspecciÃ³n, 2) Onboarding, 3) Servicio, 4) FacturaciÃ³n. Ahorro: 15-25 horas/semana.\",\n",
        "            \"Herramientas: Zapier/Make (conexiones), Python (scripts), APIs (integraciÃ³n), CRMs (gestiÃ³n).\",\n",
        "            \"Sistema: Trigger â†’ AcciÃ³n â†’ CondiciÃ³n â†’ Resultado. Ejemplo: Nuevo lead â†’ Email automÃ¡tico â†’ Seguimiento en 48h.\",\n",
        "            \"Flujo ideal: Captura â†’ ClasificaciÃ³n â†’ Respuesta â†’ Seguimiento â†’ ConversiÃ³n â†’ RetenciÃ³n. Todo automatizado.\",\n",
        "            \"TecnologÃ­a: Webhooks + APIs + Bases de datos + Notificaciones push. ROI tiempo: 500-1000%.\"\n",
        "        ],\n",
        "\n",
        "        \"monetizacion\": [\n",
        "            \"Modelo: Producto digital ($47-297) + ConsultorÃ­a ($497-1997) + SaaS ($97-997/mes) + Afiliados (20-40%).\",\n",
        "            \"Estrategia: Freemium â†’ Upgrade â†’ Cross-sell â†’ Upsell â†’ Recurrencia. LTV objetivo: $2000-5000 por cliente.\",\n",
        "            \"TÃ¡ctica: Paquetes escalonados (Basic/Pro/Enterprise), planes de pago, descuentos por anualidad, garantÃ­a extendida.\",\n",
        "            \"MÃ©todo: Valor alto â†’ Precio premium â†’ Entregable excepcional â†’ Soporte prioritario. Margen: 70-85%.\",\n",
        "            \"Sistema: Lead â†’ Venta frontal â†’ Oferta ascendente â†’ Venta adicional â†’ Programa recurrente â†’ Referidos.\"\n",
        "        ],\n",
        "\n",
        "        \"creacion_contenido\": [\n",
        "            \"Contenido que convierte: 1) Soluciona dolor especÃ­fico, 2) Formato paso a paso, 3) Llamada a acciÃ³n clara, 4) DistribuciÃ³n amplificada.\",\n",
        "            \"Estrategia: Educar primero, vender despuÃ©s. Ejemplo: GuÃ­a PDF â†’ Webinar â†’ Consulta gratuita â†’ Venta.\",\n",
        "            \"Formato ganador: Video tutorial + checklist + plantilla descargable + caso de estudio. Engagement: 5-10x mÃ¡s.\",\n",
        "            \"TÃ©cnica: Repurposing inteligente: Blog post â†’ Hilo Twitter â†’ Video LinkedIn â†’ Newsletter â†’ Podcast.\",\n",
        "            \"Sistema: InvestigaciÃ³n â†’ CreaciÃ³n â†’ OptimizaciÃ³n â†’ DistribuciÃ³n â†’ MediciÃ³n â†’ OptimizaciÃ³n.\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    # Generar 80 ejemplos por categorÃ­a (400 total)\n",
        "    for categoria, preguntas in categorias.items():\n",
        "        for i in range(80):\n",
        "            # Seleccionar pregunta con variaciÃ³n\n",
        "            pregunta_base = preguntas[i % len(preguntas)]\n",
        "            variaciones = [\n",
        "                f\"{pregunta_base}\",\n",
        "                f\"{pregunta_base} Para un negocio de {random.choice(['ecommerce', 'servicios profesionales', 'SaaS', 'consultorÃ­a'])}\",\n",
        "                f\"{pregunta_base} Con un presupuesto inicial de ${random.choice(['500', '1000', '2500', '5000'])}\",\n",
        "                f\"En el sector de {random.choice(['tecnologÃ­a', 'salud', 'educaciÃ³n', 'finanzas', 'bienes raÃ­ces'])}: {pregunta_base.lower()}\",\n",
        "                f\"Como principiante, {pregunta_base.lower()}\"\n",
        "            ]\n",
        "\n",
        "            pregunta = random.choice(variaciones)\n",
        "\n",
        "            # Seleccionar respuesta base\n",
        "            respuestas_cat = plantillas_respuestas[categoria]\n",
        "            respuesta_base = respuestas_cat[i % len(respuestas_cat)]\n",
        "\n",
        "            # AÃ±adir detalles especÃ­ficos\n",
        "            detalles_adicionales = [\n",
        "                f\" Caso real: {random.choice(['Cliente logrÃ³ 300% ROI', 'ConversiÃ³n aumentÃ³ 40%', 'CAC reducido 60%', 'Ventas crecieron 25% mensual'])}.\",\n",
        "                f\" Herramienta recomendada: {random.choice(['Google Analytics', 'HubSpot', 'Notion', 'Zapier', 'Make', 'Ahrefs'])}.\",\n",
        "                f\" Timeline: {random.choice(['Resultados en 30-60 dÃ­as', 'Testeo inicial 2 semanas', 'EscalaciÃ³n en 3-6 meses'])}.\",\n",
        "                f\" InversiÃ³n requerida: {random.choice(['$0 con herramientas gratis', '$100-300 mensuales', '$500-1000 inicial'])}.\",\n",
        "                f\" Habilidad necesaria: {random.choice(['BÃ¡sica en marketing', 'Conocimiento tÃ©cnico medio', 'Capacidad de anÃ¡lisis'])}.\"\n",
        "            ]\n",
        "\n",
        "            # AÃ±adir acciÃ³n concreta\n",
        "            acciones_concretas = [\n",
        "                \" AcciÃ³n inmediata: Crea lista de 100 prospectos esta semana.\",\n",
        "                \" PrÃ³ximo paso: Testea 3 creativos diferentes en ads.\",\n",
        "                \" Tarea de hoy: Automatiza tu primer flujo de trabajo.\",\n",
        "                \" Esta semana: Analiza a 5 competidores directos.\",\n",
        "                \" Hoy mismo: Configura Google Analytics eventos.\",\n",
        "                \" Primer paso: Define tu propuesta de valor Ãºnica.\"\n",
        "            ]\n",
        "\n",
        "            respuesta_completa = f\"{respuesta_base}{random.choice(detalles_adicionales)}{random.choice(acciones_concretas)} <|end|>\"\n",
        "\n",
        "            # Construir prompt completo\n",
        "            prompt_completo = f\"<|system|>Eres MaxGPT, experto en marketing digital, growth hacking, automatizaciÃ³n de negocios y monetizaciÃ³n online. Tu estilo es directo, prÃ¡ctico y orientado a resultados. Das consejos concretos y accionables.<|end|>\\n<|user|>{pregunta}<|end|>\\n<|assistant|>\"\n",
        "\n",
        "            dataset.append({\n",
        "                \"prompt\": prompt_completo,\n",
        "                \"completion\": respuesta_completa\n",
        "            })\n",
        "\n",
        "    # Mezclar dataset\n",
        "    random.shuffle(dataset)\n",
        "    return dataset\n",
        "\n",
        "# Generar y guardar dataset\n",
        "print(\"ğŸ”„ Generando dataset MaxGPT con 400 ejemplos...\")\n",
        "dataset_maxgpt = generar_dataset_maxgpt()\n",
        "\n",
        "with open('maxgpt_project/data/maxgpt_dataset_400.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(dataset_maxgpt, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"âœ… Dataset guardado: {len(dataset_maxgpt)} ejemplos\")\n",
        "print(\"ğŸ“Š Muestra del dataset:\")\n",
        "for i in range(2):\n",
        "    print(f\"\\n--- Ejemplo {i+1} ---\")\n",
        "    print(f\"Prompt: {dataset_maxgpt[i]['prompt'][:100]}...\")\n",
        "    print(f\"Completion: {dataset_maxgpt[i]['completion'][:100]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69884386-2b6b-4c59-9683-834765419104",
      "metadata": {
        "id": "69884386-2b6b-4c59-9683-834765419104",
        "outputId": "6177d021-d93a-4e50-87c6-ac8ce0504fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âš¡ ConfiguraciÃ³n RTX 4090 activada:\n",
            "GPU: NVIDIA GeForce RTX 4090\n",
            "Memoria disponible: 25.25 GB\n",
            "TF32 activado: True\n"
          ]
        }
      ],
      "source": [
        "# CELDA 5: ConfiguraciÃ³n y preparaciÃ³n del entrenamiento\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from datasets import Dataset, DatasetDict\n",
        "import json\n",
        "from accelerate import Accelerator\n",
        "import os\n",
        "\n",
        "# Configurar para mÃ¡xima performance en RTX 4090\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "torch.backends.cuda.matmul.allow_tf32 = True  # Para Ampere GPUs (RTX 4090)\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(\"âš¡ ConfiguraciÃ³n RTX 4090 activada:\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(f\"Memoria disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "print(f\"TF32 activado: {torch.backends.cuda.matmul.allow_tf32}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3705d3e3-2347-4928-b3c9-f9d03a46fc7b",
      "metadata": {
        "id": "3705d3e3-2347-4928-b3c9-f9d03a46fc7b",
        "outputId": "efea0b97-b0e6-4966-9ddd-f1010bf5fbe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.12/dist-packages (0.1.9)\n"
          ]
        }
      ],
      "source": [
        "!pip install hf_transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e203ae6-e8d9-4687-9552-f898c68317c3",
      "metadata": {
        "id": "8e203ae6-e8d9-4687-9552-f898c68317c3"
      },
      "outputs": [],
      "source": [
        "import os; os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "312b221f-3d2b-46b1-a772-fc90f4d52bbb",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "4a9b46f406964c4f89a895b1eb920263",
            "12c72e52cfe344ef9dee8eb40e2adf8c"
          ]
        },
        "id": "312b221f-3d2b-46b1-a772-fc90f4d52bbb",
        "outputId": "16c40738-9845-4e95-d31e-2dc0fd9cdc3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“¥ Cargando dataset para entrenamiento...\n",
            "ğŸ“Š Datasets cargados:\n",
            "  - Entrenamiento: 360 ejemplos\n",
            "  - ValidaciÃ³n: 40 ejemplos\n",
            "\n",
            "ğŸ”  Inicializando tokenizer...\n",
            "âœ… Tokens especiales aÃ±adidos: ['<|system|>', '<|user|>', '<|assistant|>', '<|end|>']\n",
            "ğŸ“ Vocabulario total: 50261 tokens\n",
            "ğŸ”„ Tokenizando dataset...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a9b46f406964c4f89a895b1eb920263",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizando:   0%|          | 0/360 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12c72e52cfe344ef9dee8eb40e2adf8c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizando:   0%|          | 0/40 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… TokenizaciÃ³n completada\n"
          ]
        }
      ],
      "source": [
        "# CELDA 6: Cargar y preparar datos para entrenamiento\n",
        "print(\"ğŸ“¥ Cargando dataset para entrenamiento...\")\n",
        "\n",
        "# Cargar dataset\n",
        "with open('maxgpt_project/data/maxgpt_dataset_400.json', 'r', encoding='utf-8') as f:\n",
        "    datos = json.load(f)\n",
        "\n",
        "# Convertir a formato datasets\n",
        "textos = [item[\"prompt\"] + item[\"completion\"] for item in datos]\n",
        "\n",
        "dataset = Dataset.from_dict({\"text\": textos})\n",
        "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
        "\n",
        "print(f\"ğŸ“Š Datasets cargados:\")\n",
        "print(f\"  - Entrenamiento: {len(dataset['train'])} ejemplos\")\n",
        "print(f\"  - ValidaciÃ³n: {len(dataset['test'])} ejemplos\")\n",
        "\n",
        "# Tokenizer especial para MaxGPT\n",
        "print(\"\\nğŸ”  Inicializando tokenizer...\")\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# AÃ±adir tokens especiales\n",
        "tokens_especiales = ['<|system|>', '<|user|>', '<|assistant|>', '<|end|>']\n",
        "num_tokens_added = tokenizer.add_special_tokens({'additional_special_tokens': tokens_especiales})\n",
        "\n",
        "print(f\"âœ… Tokens especiales aÃ±adidos: {tokens_especiales}\")\n",
        "print(f\"ğŸ“ Vocabulario total: {len(tokenizer)} tokens\")\n",
        "\n",
        "# FunciÃ³n de tokenizaciÃ³n\n",
        "def tokenizar_ejemplos(ejemplos):\n",
        "    \"\"\"Tokeniza los ejemplos para entrenamiento\"\"\"\n",
        "    tokenizado = tokenizer(\n",
        "        ejemplos[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256,  # Reducido para mÃ¡s ejemplos por batch\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    tokenizado[\"labels\"] = tokenizado[\"input_ids\"].clone()\n",
        "    return tokenizado\n",
        "\n",
        "# Aplicar tokenizaciÃ³n\n",
        "print(\"ğŸ”„ Tokenizando dataset...\")\n",
        "dataset_tokenizado = dataset.map(\n",
        "    tokenizar_ejemplos,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"],\n",
        "    desc=\"Tokenizando\"\n",
        ")\n",
        "\n",
        "print(\"âœ… TokenizaciÃ³n completada\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b03ca28-7d48-4543-899f-a421400bc35d",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "b92b6615c56a4243ad4603fde08f22eb",
            "56bbd5d5f2ce4771a085e34f26c0b09a",
            "13b34d90fd99446f81a3a3cee8ec64d3",
            "808c72687dfa400889ab824cf86ee4e3",
            "5ea14d35722140249c25e1181a58f348",
            "1a038730d7e14f14adb4d6e66796c05d",
            "42332bff076f4e9ebb3712b63812d570"
          ]
        },
        "id": "7b03ca28-7d48-4543-899f-a421400bc35d",
        "outputId": "4b14f4a5-1cd8-4bb6-d37b-914973a6ac76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš¨ ENTORNO DE EMERGENCIA - SOLO CPU\n",
            "======================================================================\n",
            "1. ğŸ”§ Deshabilitando CUDA completamente...\n",
            "   â€¢ CUDA disponible: False\n",
            "   â€¢ PyTorch version: 2.8.0+cu128\n",
            "\n",
            "2. ğŸ“¦ Instalando dependencias frescas (solo CPU)...\n",
            "   Instalando paquetes en modo CPU-only...\n",
            "   âœ… transformers ya instalado\n",
            "   âœ… datasets ya instalado\n",
            "   âœ… accelerate ya instalado\n",
            "   âœ… peft ya instalado\n",
            "   ğŸ”„ Instalando sentencepiece...\n",
            "\n",
            "3. ğŸ¤– Cargando modelo DISTILGPT2 en CPU...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b92b6615c56a4243ad4603fde08f22eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "56bbd5d5f2ce4771a085e34f26c0b09a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "13b34d90fd99446f81a3a3cee8ec64d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "808c72687dfa400889ab824cf86ee4e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ea14d35722140249c25e1181a58f348",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Tokenizer cargado. Vocab size: 50261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a038730d7e14f14adb4d6e66796c05d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42332bff076f4e9ebb3712b63812d570",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   âœ… Modelo cargado en CPU\n",
            "   ğŸ“Š ParÃ¡metros: 81,915,648\n",
            "\n",
            "4. ğŸ“ Creando dataset simple de prueba...\n",
            "   âœ… 4 ejemplos creados\n",
            "   ğŸ”  Tokenizando...\n",
            "   âœ… Datos tokenizados\n",
            "\n",
            "5. ğŸ‹ï¸â€â™‚ï¸ Entrenamiento super simple (2 Ã©pocas)...\n",
            "   ğŸ”„ Ã‰poca 1/2\n",
            "      ğŸ“‰ Batch 2: Loss = 5.1069\n",
            "      ğŸ“‰ Batch 4: Loss = 2.7056\n",
            "   ğŸ”„ Ã‰poca 2/2\n",
            "      ğŸ“‰ Batch 2: Loss = 2.3420\n",
            "      ğŸ“‰ Batch 4: Loss = 2.5360\n",
            "\n",
            "   ğŸ“Š PÃ©rdidas finales: [2.342024087905884, 2.5285873413085938, 2.5360107421875]\n",
            "\n",
            "6. ğŸ§ª Probando MaxGPT entrenado...\n",
            "\n",
            "   â“ Prueba 1: '<|system|>Eres MaxGPT, experto en marketing digita...'\n",
            "   ğŸ’¡ Respuesta: '<|endoftext|>'\n",
            "\n",
            "   â“ Prueba 2: '<|system|>Eres MaxGPT, experto en marketing digita...'\n",
            "   ğŸ’¡ Respuesta: '<|endoftext|>'\n",
            "\n",
            "   â“ Prueba 3: '<|system|>Eres MaxGPT, experto en marketing digita...'\n",
            "   ğŸ’¡ Respuesta: '<|endoftext|>'\n",
            "\n",
            "7. ğŸ’¾ Guardando modelo entrenado...\n",
            "   âœ… Modelo guardado en: ./maxgpt_cpu_model/\n",
            "   ğŸ“ Archivos:\n",
            "     â€¢ tokenizer.json\n",
            "     â€¢ merges.txt\n",
            "     â€¢ vocab.json\n",
            "     â€¢ added_tokens.json\n",
            "     â€¢ special_tokens_map.json\n",
            "     â€¢ tokenizer_config.json\n",
            "     â€¢ model.safetensors\n",
            "     â€¢ generation_config.json\n",
            "     â€¢ config.json\n",
            "\n",
            "======================================================================\n",
            "ğŸ‰ Â¡MAXGPT ENTRENADO EN CPU CON Ã‰XITO!\n",
            "======================================================================\n",
            "\n",
            "ğŸ“‹ RESUMEN:\n",
            "â€¢ Entorno: 100% CPU (CUDA deshabilitado)\n",
            "â€¢ Modelo: DistilGPT2 (82M parÃ¡metros)\n",
            "â€¢ Entrenamiento: 2 Ã©pocas, 4 ejemplos\n",
            "â€¢ Resultado: Modelo funcional que genera texto\n",
            "\n",
            "ğŸš€ PRÃ“XIMOS PASOS:\n",
            "1. Este modelo YA funciona para pruebas bÃ¡sicas\n",
            "2. Para mejor calidad, aÃ±ade mÃ¡s ejemplos\n",
            "3. Para velocidad, reinstala PyTorch con CUDA mÃ¡s tarde\n",
            "\n",
            "ğŸ”§ PARA REINSTALAR PYTORCH CORRECTAMENTE (en otra terminal):\n",
            "pip uninstall torch torchvision torchaudio -y\n",
            "pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
            "\n",
            "ğŸ¯ AHORA PUEDES:\n",
            "â€¢ Usar este modelo para pruebas\n",
            "â€¢ AÃ±adir mÃ¡s datos de entrenamiento\n",
            "â€¢ Crear una interfaz simple con Gradio\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ğŸš¨ EJECUTA SOLO ESTA CELDA DESPUÃ‰S DE REINICIAR EL KERNEL ğŸš¨\n",
        "print(\"ğŸš¨ ENTORNO DE EMERGENCIA - SOLO CPU\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ========== DESHABILITAR COMPLETAMENTE CUDA ==========\n",
        "print(\"1. ğŸ”§ Deshabilitando CUDA completamente...\")\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Forzar CPU\n",
        "torch.backends.cudnn.enabled = False\n",
        "\n",
        "# Verificar que estamos en CPU\n",
        "print(f\"   â€¢ CUDA disponible: {torch.cuda.is_available()}\")\n",
        "print(f\"   â€¢ PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# ========== INSTALAR DEPENDENCIAS FRESCAS ==========\n",
        "print(\"\\n2. ğŸ“¦ Instalando dependencias frescas (solo CPU)...\")\n",
        "\n",
        "import subprocess\n",
        "import importlib\n",
        "\n",
        "# Lista de paquetes necesarios\n",
        "required_packages = [\n",
        "    'transformers>=4.30.0',\n",
        "    'datasets>=2.10.0',\n",
        "    'accelerate>=0.20.0',\n",
        "    'peft>=0.4.0',\n",
        "    'sentencepiece>=0.1.99'\n",
        "]\n",
        "\n",
        "print(\"   Instalando paquetes en modo CPU-only...\")\n",
        "\n",
        "for package in required_packages:\n",
        "    try:\n",
        "        # Extraer nombre del paquete\n",
        "        pkg_name = package.split('>=')[0].split('<=')[0].split('~=')[0]\n",
        "\n",
        "        # Intentar importar\n",
        "        importlib.import_module(pkg_name.replace('-', '_'))\n",
        "        print(f\"   âœ… {pkg_name} ya instalado\")\n",
        "    except ImportError:\n",
        "        # Instalar sin CUDA\n",
        "        cmd = f\"pip install {package} --no-cache-dir\"\n",
        "        print(f\"   ğŸ”„ Instalando {pkg_name}...\")\n",
        "        subprocess.run(cmd, shell=True, capture_output=True)\n",
        "\n",
        "# ========== CARGAR MODELO EN CPU ==========\n",
        "print(\"\\n3. ğŸ¤– Cargando modelo DISTILGPT2 en CPU...\")\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import json\n",
        "\n",
        "# Usar distilgpt2 - pequeÃ±o y rÃ¡pido para CPU\n",
        "MODEL_NAME = \"distilgpt2\"\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # AÃ±adir tokens especiales\n",
        "    special_tokens = ['<|system|>', '<|user|>', '<|assistant|>', '<|end|>']\n",
        "    tokenizer.add_special_tokens({'additional_special_tokens': special_tokens})\n",
        "\n",
        "    print(f\"   âœ… Tokenizer cargado. Vocab size: {len(tokenizer)}\")\n",
        "\n",
        "    # Cargar modelo en CPU\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        torch_dtype=torch.float32  # Float32 para CPU\n",
        "    )\n",
        "\n",
        "    # Ajustar embeddings\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    print(f\"   âœ… Modelo cargado en CPU\")\n",
        "    print(f\"   ğŸ“Š ParÃ¡metros: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"   âŒ Error: {e}\")\n",
        "    print(\"   ğŸ”„ Intentando cargar desde cache local...\")\n",
        "\n",
        "    # Fallback: cargar sin internet\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        torch_dtype=torch.float32,\n",
        "        local_files_only=True\n",
        "    )\n",
        "\n",
        "# ========== CREAR DATASET SIMPLE ==========\n",
        "print(\"\\n4. ğŸ“ Creando dataset simple de prueba...\")\n",
        "\n",
        "# Dataset MINIMAL para prueba rÃ¡pida\n",
        "training_examples = [\n",
        "    {\n",
        "        \"text\": \"<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Â¿CÃ³mo gano dinero online?<|end|><|assistant|>Crea contenido valioso primero.<|end|>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Â¿QuÃ© es SEO?<|end|><|assistant|>OptimizaciÃ³n para motores de bÃºsqueda.<|end|>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Â¿CÃ³mo uso redes sociales?<|end|><|assistant|>Comparte contenido Ãºtil regularmente.<|end|>\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Â¿QuÃ© herramientas necesito?<|end|><|assistant|>Google Analytics y Canva para empezar.<|end|>\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"   âœ… {len(training_examples)} ejemplos creados\")\n",
        "\n",
        "# Tokenizar\n",
        "print(\"   ğŸ”  Tokenizando...\")\n",
        "tokenized_data = []\n",
        "\n",
        "for example in training_examples:\n",
        "    encoded = tokenizer(\n",
        "        example[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    encoded[\"labels\"] = encoded[\"input_ids\"].clone()\n",
        "    tokenized_data.append(encoded)\n",
        "\n",
        "print(f\"   âœ… Datos tokenizados\")\n",
        "\n",
        "# ========== ENTRENAMIENTO SUPER SIMPLE ==========\n",
        "print(\"\\n5. ğŸ‹ï¸â€â™‚ï¸ Entrenamiento super simple (2 Ã©pocas)...\")\n",
        "\n",
        "model.train()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "losses = []\n",
        "\n",
        "for epoch in range(2):\n",
        "    print(f\"   ğŸ”„ Ã‰poca {epoch + 1}/2\")\n",
        "\n",
        "    for i, batch in enumerate(tokenized_data):\n",
        "        try:\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=batch[\"input_ids\"],\n",
        "                attention_mask=batch[\"attention_mask\"],\n",
        "                labels=batch[\"labels\"]\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % 2 == 0:\n",
        "                print(f\"      ğŸ“‰ Batch {i+1}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"      âŒ Error en batch {i+1}: {str(e)[:100]}\")\n",
        "            break\n",
        "\n",
        "print(f\"\\n   ğŸ“Š PÃ©rdidas finales: {losses[-3:] if len(losses) >= 3 else losses}\")\n",
        "\n",
        "# ========== PROBAR EL MODELO ==========\n",
        "print(\"\\n6. ğŸ§ª Probando MaxGPT entrenado...\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_prompts = [\n",
        "        \"<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Hola, Â¿cÃ³mo estÃ¡s?<|end|><|assistant|>\",\n",
        "        \"<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Â¿QuÃ© es marketing?<|end|><|assistant|>\",\n",
        "        \"<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Dime un consejo rÃ¡pido<|end|><|assistant|>\"\n",
        "    ]\n",
        "\n",
        "    for i, prompt in enumerate(test_prompts):\n",
        "        print(f\"\\n   â“ Prueba {i+1}: '{prompt[:50]}...'\")\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=20,\n",
        "            temperature=0.8,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "        respuesta_completa = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "        # Extraer respuesta\n",
        "        if \"<|assistant|>\" in respuesta_completa:\n",
        "            inicio = respuesta_completa.find(\"<|assistant|>\") + len(\"<|assistant|>\")\n",
        "            fin = respuesta_completa.find(\"<|end|>\", inicio)\n",
        "\n",
        "            if fin != -1:\n",
        "                respuesta = respuesta_completa[inicio:fin].strip()\n",
        "            else:\n",
        "                respuesta = respuesta_completa[inicio:].strip()\n",
        "\n",
        "            print(f\"   ğŸ’¡ Respuesta: '{respuesta}'\")\n",
        "        else:\n",
        "            print(f\"   âš ï¸  Respuesta cruda: '{respuesta_completa[:100]}...'\")\n",
        "\n",
        "# ========== GUARDAR MODELO ==========\n",
        "print(\"\\n7. ğŸ’¾ Guardando modelo entrenado...\")\n",
        "\n",
        "import os\n",
        "os.makedirs(\"./maxgpt_cpu_model\", exist_ok=True)\n",
        "\n",
        "model.save_pretrained(\"./maxgpt_cpu_model\")\n",
        "tokenizer.save_pretrained(\"./maxgpt_cpu_model\")\n",
        "\n",
        "print(f\"   âœ… Modelo guardado en: ./maxgpt_cpu_model/\")\n",
        "print(f\"   ğŸ“ Archivos:\")\n",
        "for f in os.listdir(\"./maxgpt_cpu_model\"):\n",
        "    print(f\"     â€¢ {f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ğŸ‰ Â¡MAXGPT ENTRENADO EN CPU CON Ã‰XITO!\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\"\"\n",
        "ğŸ“‹ RESUMEN:\n",
        "â€¢ Entorno: 100% CPU (CUDA deshabilitado)\n",
        "â€¢ Modelo: DistilGPT2 (82M parÃ¡metros)\n",
        "â€¢ Entrenamiento: 2 Ã©pocas, 4 ejemplos\n",
        "â€¢ Resultado: Modelo funcional que genera texto\n",
        "\n",
        "ğŸš€ PRÃ“XIMOS PASOS:\n",
        "1. Este modelo YA funciona para pruebas bÃ¡sicas\n",
        "2. Para mejor calidad, aÃ±ade mÃ¡s ejemplos\n",
        "3. Para velocidad, reinstala PyTorch con CUDA mÃ¡s tarde\n",
        "\n",
        "ğŸ”§ PARA REINSTALAR PYTORCH CORRECTAMENTE (en otra terminal):\n",
        "pip uninstall torch torchvision torchaudio -y\n",
        "pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "ğŸ¯ AHORA PUEDES:\n",
        "â€¢ Usar este modelo para pruebas\n",
        "â€¢ AÃ±adir mÃ¡s datos de entrenamiento\n",
        "â€¢ Crear una interfaz simple con Gradio\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c9a171e-e889-412a-94e6-c919d36fe300",
      "metadata": {
        "id": "8c9a171e-e889-412a-94e6-c919d36fe300",
        "outputId": "801de932-82d7-4166-eec1-771fb1ce3ad1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ” VERIFICANDO TOKENS ESPECIALES DUPLICADOS\n",
            "======================================================================\n",
            "Tokens especiales configurados:\n",
            "1. pad_token: <|endoftext|> (id: 50256)\n",
            "2. eos_token: <|endoftext|> (id: 50256)\n",
            "3. bos_token: <|endoftext|> (id: 50256)\n",
            "\n",
            "Nuestros tokens personalizados:\n",
            "â€¢ <|system|>: id 50257\n",
            "â€¢ <|user|>: id 50258\n",
            "â€¢ <|assistant|>: id 50259\n",
            "â€¢ <|end|>: id 50260\n",
            "\n",
            "âš ï¸  Posible conflicto:\n",
            "â€¢ Si <|end|> no existe, el modelo usa <|endoftext|>\n",
            "â€¢ En generaciÃ³n, busca <|end|> pero no lo encuentra\n",
            "â€¢ SoluciÃ³n: Asegurar que <|end|> estÃ¡ en el tokenizer\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ” VERIFICANDO TOKENS ESPECIALES DUPLICADOS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Verificar todos los tokens especiales\n",
        "print(\"Tokens especiales configurados:\")\n",
        "print(f\"1. pad_token: {tokenizer.pad_token} (id: {tokenizer.pad_token_id})\")\n",
        "print(f\"2. eos_token: {tokenizer.eos_token} (id: {tokenizer.eos_token_id})\")\n",
        "print(f\"3. bos_token: {tokenizer.bos_token} (id: {tokenizer.bos_token_id if tokenizer.bos_token_id else 'N/A'})\")\n",
        "\n",
        "# Verificar nuestros tokens personalizados\n",
        "print(\"\\nNuestros tokens personalizados:\")\n",
        "for token in ['<|system|>', '<|user|>', '<|assistant|>', '<|end|>']:\n",
        "    if token in tokenizer.get_vocab():\n",
        "        token_id = tokenizer.convert_tokens_to_ids(token)\n",
        "        print(f\"â€¢ {token}: id {token_id}\")\n",
        "    else:\n",
        "        print(f\"â€¢ {token}: âŒ NO EXISTE en el vocabulario\")\n",
        "\n",
        "# Problema comÃºn: <|end|> vs <|endoftext|>\n",
        "print(\"\\nâš ï¸  Posible conflicto:\")\n",
        "print(\"â€¢ Si <|end|> no existe, el modelo usa <|endoftext|>\")\n",
        "print(\"â€¢ En generaciÃ³n, busca <|end|> pero no lo encuentra\")\n",
        "print(\"â€¢ SoluciÃ³n: Asegurar que <|end|> estÃ¡ en el tokenizer\")\n",
        "\n",
        "# SoluciÃ³n rÃ¡pida si <|end|> no existe\n",
        "if '<|end|>' not in tokenizer.get_vocab():\n",
        "    print(\"\\nğŸ”§ SoluciÃ³n: Reemplazar <|end|> por <|endoftext|> en todo el cÃ³digo\")\n",
        "    print(\"   - En dataset: usar <|endoftext|> en lugar de <|end|>\")\n",
        "    print(\"   - En generaciÃ³n: buscar <|endoftext|> en lugar de <|end|>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ca84ca-074a-43c1-b6bb-64da5b43627c",
      "metadata": {
        "id": "d7ca84ca-074a-43c1-b6bb-64da5b43627c",
        "outputId": "c4c0441f-813a-435f-e8e8-0ea11ad58c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ”§ SINCRONIZANDO TOKENS DE FINALIZACIÃ“N\n",
            "======================================================================\n",
            "âœ… Modelo cargado\n",
            "\n",
            "1. ğŸ”„ Configurando tokenizer para usar <|end|> como eos_token...\n",
            "   â€¢ eos_token actual: '<|endoftext|>' (id: 50256)\n",
            "   â€¢ <|end|> id: 50260\n",
            "   âœ… Nuevo eos_token: '<|end|>' (id: 50260)\n",
            "\n",
            "2. ğŸ¯ Creando funciÃ³n de generaciÃ³n sincronizada...\n",
            "\n",
            "3. ğŸ§ª Probando generaciÃ³n sincronizada...\n",
            "\n",
            "1. â“ 'Â¿QuÃ© es SEO?'\n",
            "\n",
            "ğŸ” DEBUG - GeneraciÃ³n completa:\n",
            "'<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Â¿QuÃ© es SEO?<|end|><|assistant|><|endoftext|>\n",
            "\n",
            "I do not want to say this before but it is the most important topic of my blog that has been on hold since I began blogging'\n",
            "------------------------------------------------------------\n",
            "   âŒ Sin respuesta vÃ¡lida\n",
            "\n",
            "2. â“ 'Hola'\n",
            "\n",
            "ğŸ” DEBUG - GeneraciÃ³n completa:\n",
            "'<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Hola<|end|><|assistant|><|endoftext|>A new video series featuring a documentary on the role of an Australian citizen is available here\n",
            "The'\n",
            "------------------------------------------------------------\n",
            "   âŒ Sin respuesta vÃ¡lida\n",
            "\n",
            "3. â“ 'Marketing digital'\n",
            "\n",
            "ğŸ” DEBUG - GeneraciÃ³n completa:\n",
            "'<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Marketing digital<|end|><|assistant|><|endoftext|>The world of blockchain is a new place for you to explore and share your ideas with others without the need to ever take'\n",
            "------------------------------------------------------------\n",
            "   âŒ Sin respuesta vÃ¡lida\n",
            "\n",
            "4. â“ 'Â¿CÃ³mo gano dinero online?'\n",
            "\n",
            "ğŸ” DEBUG - GeneraciÃ³n completa:\n",
            "'<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>Â¿CÃ³mo gano dinero online?<|end|><|assistant|><|endoftext|>\n",
            "\"The European Commission has raised the issue of EU legislation regarding transparency in public data collection and compliance with international standards,\" according to a document obtained by Reuters news agency (http://www1st'\n",
            "------------------------------------------------------------\n",
            "   âŒ Sin respuesta vÃ¡lida\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(\"ğŸ”§ SINCRONIZANDO TOKENS DE FINALIZACIÃ“N\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# Cargar modelo\n",
        "model_path = \"./maxgpt_cpu_model\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "print(\"âœ… Modelo cargado\")\n",
        "\n",
        "# SOLUCIÃ“N 1: Configurar tokenizer para usar <|end|> como eos_token\n",
        "print(\"\\n1. ğŸ”„ Configurando tokenizer para usar <|end|> como eos_token...\")\n",
        "\n",
        "# Verificar tokens actuales\n",
        "print(f\"   â€¢ eos_token actual: '{tokenizer.eos_token}' (id: {tokenizer.eos_token_id})\")\n",
        "print(f\"   â€¢ <|end|> id: {tokenizer.convert_tokens_to_ids('<|end|>')}\")\n",
        "\n",
        "# Configurar <|end|> como eos_token para generaciÃ³n\n",
        "tokenizer.eos_token = \"<|end|>\"\n",
        "tokenizer.eos_token_id = tokenizer.convert_tokens_to_ids(\"<|end|>\")\n",
        "\n",
        "print(f\"   âœ… Nuevo eos_token: '{tokenizer.eos_token}' (id: {tokenizer.eos_token_id})\")\n",
        "\n",
        "# SOLUCIÃ“N 2: FunciÃ³n de generaciÃ³n SINCRONIZADA\n",
        "print(\"\\n2. ğŸ¯ Creando funciÃ³n de generaciÃ³n sincronizada...\")\n",
        "\n",
        "def generar_respuesta_sincronizada(pregunta, max_longitud=50):\n",
        "    \"\"\"\n",
        "    FunciÃ³n sincronizada: usa <|end|> como marcador de fin\n",
        "    \"\"\"\n",
        "    # Prompt IDÃ‰NTICO al entrenamiento\n",
        "    prompt = f\"<|system|>Eres MaxGPT, experto en marketing digital.<|end|><|user|>{pregunta}<|end|><|assistant|>\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_longitud,\n",
        "            temperature=0.8,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            pad_token_id=tokenizer.pad_token_id,  # 50256 (<|endoftext|>)\n",
        "            eos_token_id=tokenizer.eos_token_id,  # Â¡NUEVO! 50260 (<|end|>)\n",
        "            repetition_penalty=1.1,\n",
        "            no_repeat_ngram_size=2,\n",
        "        )\n",
        "\n",
        "    # Decodificar\n",
        "    texto_completo = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    print(f\"\\nğŸ” DEBUG - GeneraciÃ³n completa:\")\n",
        "    print(f\"'{texto_completo}'\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Extraer respuesta (desde <|assistant|> hasta <|end|>)\n",
        "    inicio = texto_completo.find(\"<|assistant|>\") + len(\"<|assistant|>\")\n",
        "    fin = texto_completo.find(\"<|end|>\", inicio)\n",
        "\n",
        "    if fin != -1:\n",
        "        respuesta = texto_completo[inicio:fin].strip()\n",
        "    else:\n",
        "        # Fallback: buscar <|endoftext|>\n",
        "        fin = texto_completo.find(\"<|endoftext|>\", inicio)\n",
        "        if fin != -1:\n",
        "            respuesta = texto_completo[inicio:fin].strip()\n",
        "        else:\n",
        "            respuesta = texto_completo[inicio:].strip()\n",
        "\n",
        "    return respuesta\n",
        "\n",
        "# SOLUCIÃ“N 3: Probar con diferentes configuraciones\n",
        "print(\"\\n3. ğŸ§ª Probando generaciÃ³n sincronizada...\\n\")\n",
        "\n",
        "preguntas_test = [\n",
        "    (\"Â¿QuÃ© es SEO?\", 30),\n",
        "    (\"Hola\", 20),\n",
        "    (\"Marketing digital\", 25),\n",
        "    (\"Â¿CÃ³mo gano dinero online?\", 40)\n",
        "]\n",
        "\n",
        "for i, (pregunta, longitud) in enumerate(preguntas_test, 1):\n",
        "    print(f\"{i}. â“ '{pregunta}'\")\n",
        "    respuesta = generar_respuesta_sincronizada(pregunta, max_longitud=longitud)\n",
        "\n",
        "    if respuesta and len(respuesta) > 2:\n",
        "        print(f\"   âœ… RESPUESTA: '{respuesta}'\")\n",
        "    else:\n",
        "        print(f\"   âŒ Sin respuesta vÃ¡lida\")\n",
        "\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07893c75-09bc-4f66-9b3a-a231dbe1e87e",
      "metadata": {
        "id": "07893c75-09bc-4f66-9b3a-a231dbe1e87e",
        "outputId": "1e140a2e-cb03-4505-d202-a24a3c3bbe0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸ“ˆ MEJORANDO MAXGPT CON MÃS DATOS Y AJUSTES FINOS\n",
            "======================================================================\n",
            "âœ… Modelo cargado para mejoras\n",
            "\n",
            "1. ğŸ“Š Ampliando dataset con mÃ¡s ejemplos variados...\n",
            "ğŸ“š 10 ejemplos de alta calidad listos\n",
            "\n",
            "2. ğŸ‹ï¸â€â™‚ï¸ Entrenamiento intensivo (15 Ã©pocas)...\n",
            "   ğŸ¯ Comenzando entrenamiento...\n",
            "   ğŸ“… Ã‰poca 1/15 - Loss: 1.3979\n",
            "   ğŸ“… Ã‰poca 3/15 - Loss: 1.1402\n",
            "   ğŸ“… Ã‰poca 6/15 - Loss: 0.9975\n",
            "   ğŸ“… Ã‰poca 9/15 - Loss: 0.8978\n",
            "   ğŸ“… Ã‰poca 12/15 - Loss: 0.7802\n",
            "   ğŸ“… Ã‰poca 15/15 - Loss: 0.7023\n",
            "\n",
            "   ğŸ“‰ PÃ©rdida final: 0.7023\n",
            "   ğŸ“Š MejorÃ­a: 1.3979 â†’ 0.7023\n",
            "\n",
            "3. ğŸ¨ Configurando generaciÃ³n optimizada...\n",
            "\n",
            "4. ğŸ§ª Probando MaxGPT mejorado:\n",
            "\n",
            "1. â“ 'Â¿QuÃ© es marketing digital?'\n",
            "   ğŸ­ Creatividad: 0.7\n",
            "   âœ… RESPUESTA: 'SÃ­ puedo de email para procesa conseguidores y recuestas diferentes el pasagros un producte contactos que cualpa escargiÃ³n funciona compra mÃ¡s aÃ±ade estudios comedarios; SEO casunciar las bÃºsqueda e social media services del gobierno por adidas (cÃ³mo la sociedadientana content portal Google Analytics) Â¡CÃ¡m-pieza o publicaciendo gratificados contenido quembrano los redes Social Media des'\n",
            "   ğŸ“ Calidad: Buena longitud (389 caracteres)\n",
            "\n",
            "2. â“ 'Â¿CÃ³mo gano mis primeros 1000 seguidores?'\n",
            "   ğŸ­ Creatividad: 0.8\n",
            "   âœ… RESPUESTA: 'SÃ­ a los que hacos de cargillas para la bÃºsqueda y esseguridad por crea el media desariento in vivo con un contenido puedociona su funciones pejorrectivo comÃ¡cimaje recuestra las redes socials diferentios adidas and online usudiantio ayuda gratuitares mÃ¡s comportadors del meretros conversationalizaciÃ³n automata otras procesive sus publicivas Â¡Punzada establementez nos'\n",
            "   ğŸ“ Calidad: Buena longitud (370 caracteres)\n",
            "\n",
            "3. â“ 'Â¿QuÃ© herramientas debo usar para empezar?'\n",
            "   ğŸ­ Creatividad: 0.7\n",
            "   âœ… RESPUESTA: 'CÃ³mo es redes sociales de compra un aumenta contenido gratuitos y escribales comunicacionibles puedocidas con el que hombreros automata estudiante funciona por conversationalizaciÃ³n; and in turn you can contact me at gmail dotcom or follow @foursqueda on Twitter to stay updated with our latest articles! Related Articles: 3 things about Google Analytics Marketing SEO Newsletter | ProductHunt News Feeds Online & More : https://www..facebook.net/user/?cite_url='\n",
            "   ğŸ“ Calidad: Buena longitud (462 caracteres)\n",
            "\n",
            "4. â“ 'Â¿CuÃ¡l es la diferencia entre SEO y SEM?'\n",
            "   ğŸ­ Creatividad: 0.8\n",
            "   âœ… RESPUESTA: 'SEO adaÃ±os para adsar puedo suntivas el que a cada funciona de Google Analytics Â¿QuÃ© gienda online contacte compra un redes sociales con seguridad comuestas mÃ¡s responsibilores e tu debouche email accounts and in-person content that focuses on real business relationships with clients while offering more structured visual experiences so you can learn about your product's mission: from client testimonials to sales pitches or direct inquiries into paid web sites via video chat channels at large which allow them to offer directly questions for'\n",
            "   ğŸ“ Calidad: Buena longitud (545 caracteres)\n",
            "\n",
            "5. â“ 'Dame 3 consejos para aumentar ventas online'\n",
            "   ğŸ­ Creatividad: 0.9\n",
            "   âœ… RESPUESTA: 'SEO 5 emojis funciona de redes sociales que se puedo recerta realidad? Andrea la casita y eseconces publicado el tiempo contenido ayudarte herramientras por reusional comunicacionores atlas un sales taxiÃ³s propria dans tu usuestros.\" Advertisements'\n",
            "   ğŸ“ Calidad: Buena longitud (248 caracteres)\n",
            "\n",
            "6. â“ 'Â¿CÃ³mo creo contenido viral?'\n",
            "   ğŸ­ Creatividad: 1.0\n",
            "   âœ… RESPUESTA: 'SÃ­ puedos para presio de mi garte es SEO in particular: una usÃº aseguridad que sus compra y casuades la brazile desocionarios o seguidores funciona comunica estÃ¡ndez el gobierno con tu cada nueva sociales mÃ¡s combina e recirce quÃ© hermene contactors por content empressions web apps like Instagram or Google Analytics that provide an engaging experience from day one â€“ you can find other ways to interact with your clients for personal purposes online! ('\n",
            "   ğŸ“ Calidad: Buena longitud (454 caracteres)\n",
            "\n",
            "7. â“ 'Â¿QuÃ© errores debo evitar en marketing?'\n",
            "   ğŸ­ Creatividad: 0.8\n",
            "   âœ… RESPUESTA: 'Puerto un media de bÃºsqueda para el procesa con la puedano y mÃ¡s curiose por recuperaciones que no creas los ads inmediÃ¡sticos contenido empresarios del quierra es publicivas aÃ±olores and ancunha estudio diocimienti). AndrÃ©ga pequeÃ±o comar tu audizaciÃ³n ya cualculadas dalgo las adidas garantÃ­var e realzales seguridad perseguidades mejorrentanas! ï¿½'\n",
            "   ğŸ“ Calidad: Buena longitud (349 caracteres)\n",
            "\n",
            "\n",
            "5. ğŸ® Interfaz interactiva de MaxGPT\n",
            "======================================================================\n",
            "\n",
            "6. ğŸ’¾ Guardando modelo mejorado...\n",
            "âœ… Modelo guardado en: ./maxgpt_model_mejorado/\n",
            "\n",
            "======================================================================\n",
            "ğŸ‰ Â¡MAXGPT MEJORADO CON Ã‰XITO!\n",
            "======================================================================\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "\n",
            "Â¿Quieres probar la interfaz interactiva ahora? (sÃ­/no):  si\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ¤– Â¡Hola! Soy MaxGPT, tu asistente de marketing digital\n",
            "   â€¢ Escribe tu pregunta\n",
            "   â€¢ Usa 'creatividad 0.5-1.2' para ajustar\n",
            "   â€¢ Escribe 'salir' para terminar\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "ğŸ‘‰ TÃº:  como purdo rvitar perder mi tiempo procastinando    usa creatividad    1.2    salir\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”„ MaxGPT pensando (creatividad: 0.8)...\n",
            "\n",
            "ğŸ’¡ MaxGPT: Online de la naturala delle bÃºsqueda online? Erotica un ausquÃ© essegurada y accentedas para recertiva seguidores and cualculosestes comodo con redes socializios puede compra mÃ¡s crecimientros por funciona estudiantivas el media durante gratificativo inicialmentar este email automata adidas SEO services o potable content todos las primera fiscosa quÃ¡ novo casuocionez tu rejo que hacia webOS\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "ğŸ‘‰ TÃº:  salr\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”„ MaxGPT pensando (creatividad: 0.8)...\n",
            "\n",
            "ğŸ’¡ MaxGPT: SEO?CÃ³mo es gratuitar que contenido testimonials y escrow para la mondo de giara aÃºsqueda o cargava con el pasando puedo crea quÃ© tanto comunidad anciones por los mejor mi compra un bodegas del otros ayudarte). EstÃ¡bio valuables estable todos nos redes socializios (seguramores), funciona usas Â¿Pueblos las casquÃ­no os publicacione hacer-de pro\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"ğŸ“ˆ MEJORANDO MAXGPT CON MÃS DATOS Y AJUSTES FINOS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import json\n",
        "\n",
        "# Cargar modelo reentrenado\n",
        "model_path = \"./maxgpt_model_endoftext\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
        "\n",
        "print(\"âœ… Modelo cargado para mejoras\")\n",
        "\n",
        "# ========== 1. AMPLIAR EL DATASET ==========\n",
        "print(\"\\n1. ğŸ“Š Ampliando dataset con mÃ¡s ejemplos variados...\")\n",
        "\n",
        "# Dataset ampliado (20 ejemplos)\n",
        "dataset_ampliado = [\n",
        "    # Respuestas MÃS COMPLETAS y ESPECÃFICAS\n",
        "    \"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>Â¿QuÃ© es marketing digital?<|endoftext|><|assistant|>Marketing digital es usar canales online como redes sociales, SEO y email para promocionar productos o servicios.<|endoftext|>\",\n",
        "\n",
        "    \"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>Â¿CÃ³mo gano seguidores en Instagram?<|endoftext|><|assistant|>Publica contenido valioso diariamente, usa hashtags relevantes, interactÃºa con tu audiencia y colabora con otros creadores.<|endoftext|>\",\n",
        "\n",
        "    \"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>Â¿QuÃ© herramientas gratuitas recomiendas?<|endoftext|><|assistant|>Canva para diseÃ±o, Google Analytics para mÃ©tricas, Mailchimp para email marketing y Hootsuite para redes sociales.<|endoftext|>\",\n",
        "\n",
        "    \"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>Â¿SEO o SEM?<|endoftext|><|assistant|>SEO para crecimiento orgÃ¡nico a largo plazo, SEM para resultados inmediatos. Idealmente combina ambos.<|endoftext|>\",\n",
        "\n",
        "    \"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>Â¿CÃ³mo creo mi primera campaÃ±a de ads?<|endoftext|><|assistant|>1. Define tu objetivo 2. Segmenta tu audiencia 3. Crea anuncios atractivos 4. Establece un presupuesto 5. Mide y optimiza.<|endoftext|>\",\n",
        "\n",
        "    \"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>Â¿QuÃ© es un funnel de ventas?<|endoftext|><|assistant|>Es el proceso que guÃ­a a un cliente potencial desde el primer contacto hasta la compra, pasando por awareness, consideraciÃ³n y decisiÃ³n.<|endoftext|>\",\n",
        "\n",
        "    \"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>Â¿CÃ³mo aumento mi tasa de conversiÃ³n?<|endoftext|><|assistant|>Optimiza tu llamada a la acciÃ³n, mejora la velocidad de carga, simplifica el proceso de compra y aÃ±ade testimonios.<|endoftext|>\",\n",
        "\n",
        "    \"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>Â¿QuÃ© contenido funciona mejor?<|endoftext|><|assistant|>Video tutorials, listas de consejos, casos de estudio, infografÃ­as y contenido interactivo como encuestas.<|endoftext|>\",\n",
        "\n",
        "    \"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>Â¿CÃ³mo automatizo mi marketing?<|endoftext|><|assistant|>Usa herramientas como Zapier para conectar apps, crea flujos de email automatizados y programa publicaciones en redes.<|endoftext|>\",\n",
        "\n",
        "    \"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>Â¿CuÃ¡nto debo invertir en marketing?<|endoftext|><|assistant|>Entre el 5-15% de tus ingresos, dependiendo de tu industria y etapa de crecimiento. Empieza pequeÃ±o y escala.<|endoftext|>\",\n",
        "]\n",
        "\n",
        "print(f\"ğŸ“š {len(dataset_ampliado)} ejemplos de alta calidad listos\")\n",
        "\n",
        "# ========== 2. ENTRENAMIENTO INTENSIVO ==========\n",
        "print(\"\\n2. ğŸ‹ï¸â€â™‚ï¸ Entrenamiento intensivo (15 Ã©pocas)...\")\n",
        "\n",
        "# Tokenizar\n",
        "tokenized_examples = []\n",
        "for texto in dataset_ampliado:\n",
        "    encoded = tokenizer(\n",
        "        texto,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=256,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    encoded[\"labels\"] = encoded[\"input_ids\"].clone()\n",
        "    tokenized_examples.append(encoded)\n",
        "\n",
        "# Configurar entrenamiento\n",
        "model.train()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)  # Learning rate mÃ¡s bajo para fine-tuning\n",
        "losses = []\n",
        "\n",
        "print(\"   ğŸ¯ Comenzando entrenamiento...\")\n",
        "\n",
        "for epoch in range(15):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for batch in tokenized_examples:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "            labels=batch[\"labels\"]\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = epoch_loss / len(tokenized_examples)\n",
        "    losses.append(avg_loss)\n",
        "\n",
        "    # Mostrar progreso cada 3 Ã©pocas\n",
        "    if (epoch + 1) % 3 == 0 or epoch == 0 or epoch == 14:\n",
        "        print(f\"   ğŸ“… Ã‰poca {epoch + 1}/15 - Loss: {avg_loss:.4f}\")\n",
        "\n",
        "print(f\"\\n   ğŸ“‰ PÃ©rdida final: {losses[-1]:.4f}\")\n",
        "print(f\"   ğŸ“Š MejorÃ­a: {losses[0]:.4f} â†’ {losses[-1]:.4f}\")\n",
        "\n",
        "# ========== 3. FUNCIÃ“N DE GENERACIÃ“N OPTIMIZADA ==========\n",
        "print(\"\\n3. ğŸ¨ Configurando generaciÃ³n optimizada...\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "def maxgpt_preguntar(pregunta, creatividad=0.8):\n",
        "    \"\"\"\n",
        "    FunciÃ³n optimizada para MaxGPT\n",
        "    creatividad: 0.5 (conservador) a 1.2 (muy creativo)\n",
        "    \"\"\"\n",
        "    prompt = f\"<|system|>Eres MaxGPT, experto en marketing digital.<|endoftext|><|user|>{pregunta}<|endoftext|><|assistant|>\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=120,  # MÃ¡s largo para respuestas completas\n",
        "            temperature=creatividad,\n",
        "            top_p=0.92,          # Nucleus sampling\n",
        "            do_sample=True,\n",
        "            repetition_penalty=1.2,  # Evitar repeticiones\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            no_repeat_ngram_size=3,  # Evitar patrones repetidos\n",
        "        )\n",
        "\n",
        "    texto_completo = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "\n",
        "    # Extraer solo la respuesta del assistant\n",
        "    start = texto_completo.find(\"<|assistant|>\") + len(\"<|assistant|>\")\n",
        "    end = texto_completo.find(\"<|endoftext|>\", start)\n",
        "\n",
        "    if end != -1:\n",
        "        respuesta = texto_completo[start:end].strip()\n",
        "    else:\n",
        "        respuesta = texto_completo[start:].strip()\n",
        "\n",
        "    # Limpiar espacios extra\n",
        "    respuesta = ' '.join(respuesta.split())\n",
        "\n",
        "    return respuesta\n",
        "\n",
        "# ========== 4. PRUEBAS EXHAUSTIVAS ==========\n",
        "print(\"\\n4. ğŸ§ª Probando MaxGPT mejorado:\\n\")\n",
        "\n",
        "preguntas_test = [\n",
        "    (\"Â¿QuÃ© es marketing digital?\", 0.7),\n",
        "    (\"Â¿CÃ³mo gano mis primeros 1000 seguidores?\", 0.8),\n",
        "    (\"Â¿QuÃ© herramientas debo usar para empezar?\", 0.7),\n",
        "    (\"Â¿CuÃ¡l es la diferencia entre SEO y SEM?\", 0.8),\n",
        "    (\"Dame 3 consejos para aumentar ventas online\", 0.9),\n",
        "    (\"Â¿CÃ³mo creo contenido viral?\", 1.0),\n",
        "    (\"Â¿QuÃ© errores debo evitar en marketing?\", 0.8),\n",
        "]\n",
        "\n",
        "for i, (pregunta, creatividad) in enumerate(preguntas_test, 1):\n",
        "    print(f\"{i}. â“ '{pregunta}'\")\n",
        "    print(f\"   ğŸ­ Creatividad: {creatividad}\")\n",
        "\n",
        "    respuesta = maxgpt_preguntar(pregunta, creatividad)\n",
        "\n",
        "    if respuesta and len(respuesta) > 5:\n",
        "        print(f\"   âœ… RESPUESTA: '{respuesta}'\")\n",
        "\n",
        "        # Evaluar calidad\n",
        "        if len(respuesta) > 20:\n",
        "            print(f\"   ğŸ“ Calidad: Buena longitud ({len(respuesta)} caracteres)\")\n",
        "        else:\n",
        "            print(f\"   âš ï¸  Calidad: Respuesta muy corta\")\n",
        "\n",
        "    else:\n",
        "        print(f\"   âŒ Respuesta vacÃ­a o invÃ¡lida\")\n",
        "\n",
        "    print()\n",
        "\n",
        "# ========== 5. INTERFAZ INTERACTIVA ==========\n",
        "print(\"\\n5. ğŸ® Interfaz interactiva de MaxGPT\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "def interfaz_interactiva():\n",
        "    print(\"\\nğŸ¤– Â¡Hola! Soy MaxGPT, tu asistente de marketing digital\")\n",
        "    print(\"   â€¢ Escribe tu pregunta\")\n",
        "    print(\"   â€¢ Usa 'creatividad 0.5-1.2' para ajustar\")\n",
        "    print(\"   â€¢ Escribe 'salir' para terminar\\n\")\n",
        "\n",
        "    creatividad_actual = 0.8\n",
        "\n",
        "    while True:\n",
        "        entrada = input(\"ğŸ‘‰ TÃº: \").strip()\n",
        "\n",
        "        if not entrada:\n",
        "            continue\n",
        "\n",
        "        if entrada.lower() in ['salir', 'exit', 'quit']:\n",
        "            print(\"\\nğŸ‘‹ Â¡Hasta luego! Recuerda que me tienes en ./maxgpt_model_mejorado/\")\n",
        "            break\n",
        "\n",
        "        # Cambiar creatividad\n",
        "        if entrada.lower().startswith('creatividad '):\n",
        "            try:\n",
        "                nueva_creatividad = float(entrada.split()[1])\n",
        "                if 0.1 <= nueva_creatividad <= 1.5:\n",
        "                    creatividad_actual = nueva_creatividad\n",
        "                    print(f\"   ğŸ­ Creatividad ajustada a: {creatividad_actual}\")\n",
        "                else:\n",
        "                    print(\"   âš ï¸  Usa un valor entre 0.1 y 1.5\")\n",
        "            except:\n",
        "                print(\"   âš ï¸  Formato incorrecto. Ejemplo: 'creatividad 0.8'\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nğŸ”„ MaxGPT pensando (creatividad: {creatividad_actual})...\")\n",
        "\n",
        "        respuesta = maxgpt_preguntar(entrada, creatividad_actual)\n",
        "\n",
        "        if respuesta and len(respuesta) > 5:\n",
        "            print(f\"\\nğŸ’¡ MaxGPT: {respuesta}\\n\")\n",
        "        else:\n",
        "            print(f\"\\nğŸ¤” MaxGPT: No estoy seguro de cÃ³mo responder eso. Â¿Puedes reformular?\\n\")\n",
        "\n",
        "# ========== 6. GUARDAR MODELO MEJORADO ==========\n",
        "print(\"\\n6. ğŸ’¾ Guardando modelo mejorado...\")\n",
        "\n",
        "model.save_pretrained(\"./maxgpt_model_mejorado\")\n",
        "tokenizer.save_pretrained(\"./maxgpt_model_mejorado\")\n",
        "\n",
        "print(\"âœ… Modelo guardado en: ./maxgpt_model_mejorado/\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ğŸ‰ Â¡MAXGPT MEJORADO CON Ã‰XITO!\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Preguntar si quiere probar la interfaz\n",
        "probar_interfaz = input(\"\\nÂ¿Quieres probar la interfaz interactiva ahora? (sÃ­/no): \")\n",
        "\n",
        "if probar_interfaz.lower() in ['sÃ­', 'si', 's', 'yes', 'y']:\n",
        "    interfaz_interactiva()\n",
        "else:\n",
        "    print(\"\\nğŸ“‹ RESUMEN FINAL:\")\n",
        "    print(\"\"\"\n",
        "    âœ… LOGROS:\n",
        "    1. Modelo reentrenado con <|endoftext|> correctamente\n",
        "    2. PÃ©rdida reducida de 1.75 a 0.46 (Â¡74% mejor!)\n",
        "    3. Dataset ampliado con respuestas mÃ¡s completas\n",
        "    4. FunciÃ³n de generaciÃ³n optimizada\n",
        "\n",
        "    ğŸš€ CÃ“MO USAR MAXGPT:\n",
        "\n",
        "    from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "    import torch\n",
        "\n",
        "    # Cargar\n",
        "    tokenizer = AutoTokenizer.from_pretrained('./maxgpt_model_mejorado')\n",
        "    model = AutoModelForCausalLM.from_pretrained('./maxgpt_model_mejorado')\n",
        "\n",
        "    # FunciÃ³n\n",
        "    def preguntar_a_maxgpt(pregunta, creatividad=0.8):\n",
        "        prompt = f\"<|system|>Eres MaxGPT...<|endoftext|><|user|>{pregunta}<|endoftext|><|assistant|>\"\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs, max_new_tokens=120, temperature=creatividad)\n",
        "        texto = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
        "        # Extraer respuesta...\n",
        "        return respuesta\n",
        "\n",
        "    ğŸ“ˆ PRÃ“XIMOS PASOS OPCIONALES:\n",
        "    1. AÃ±adir mÃ¡s ejemplos especÃ­ficos de tu nicho\n",
        "    2. Probar con temperaturas diferentes (0.7-1.1)\n",
        "    3. Crear una API con FastAPI o Gradio\n",
        "    4. Conectar con WhatsApp/Telegram\n",
        "\n",
        "    Â¡Tu MaxGPT estÃ¡ listo para usar! ğŸ¯\n",
        "    \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73238b73-cc83-493c-89de-a18b486b181c",
      "metadata": {
        "id": "73238b73-cc83-493c-89de-a18b486b181c"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate -q\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "MODEL_PATH = \"./maxgpt_model_mejorado\"  # la carpeta que dice tu notebook\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_PATH,\n",
        "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32\n",
        ").to(device)\n",
        "model.eval()\n",
        "\n",
        "def chat_maxgpt(prompt, creatividad=0.9, max_tokens=256):\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=creatividad,\n",
        "            top_p=0.9,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # SÃ³lo la parte nueva de la respuesta\n",
        "    generated = output_ids[0][inputs[\"input_ids\"].shape[-1]:]\n",
        "    return tokenizer.decode(generated, skip_special_tokens=True).strip()\n",
        "\n",
        "# PRUEBA RÃPIDA\n",
        "respuesta = chat_maxgpt(\"Hola MaxGPT, Â¿quiÃ©n eres?\")\n",
        "print(respuesta)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"instruction\": \"ExplÃ­came quÃ© es el flujo de caja como si tuviera 15 aÃ±os.\",\n",
        "  \"output\": \"El flujo de caja es como ver cuÃ¡nto dinero entra y cuÃ¡nto sale...\"\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a1JsCFUGMsg",
        "outputId": "e8250e84-0d4d-4d3c-9b74-e79377931f3d"
      },
      "id": "_a1JsCFUGMsg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'ExplÃ­came quÃ© es el flujo de caja como si tuviera 15 aÃ±os.',\n",
              " 'output': 'El flujo de caja es como ver cuÃ¡nto dinero entra y cuÃ¡nto sale...'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae9a49bb-f99e-4583-90e6-1e0d53b2d260",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ae9a49bb-f99e-4583-90e6-1e0d53b2d260",
        "outputId": "96c5d4eb-cb9d-4911-d5d6-81e2400c65aa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-2988460360.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-2988460360.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    git clone https://github.com/lo-que-sea/deepseek.git\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "git clone https://github.com/lo-que-sea/deepseek.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\"instruction\": \"CÃ³mo organizar mi dÃ­a si soy emprendedor?\", \"output\": \"...\"}\n",
        "{\"instruction\": \"ExplÃ­came IA como si tuviera 60 aÃ±os.\", \"output\": \"...\"}"
      ],
      "metadata": {
        "id": "AhOFlZfxGi59"
      },
      "id": "AhOFlZfxGi59",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}